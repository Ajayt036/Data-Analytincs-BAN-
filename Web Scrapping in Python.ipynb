{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a836660a",
   "metadata": {},
   "source": [
    "# Web Scrapping in Python\n",
    "\n",
    "Source: https://realpython.com/python-web-scraping-practical-introduction/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3779ec50",
   "metadata": {},
   "source": [
    "### 1. What happens when we copy all data from a website and paste in a text file?\n",
    "\n",
    "All the data is pasted in simple text form. This is not the ideal way to scrap data because if all data is simple plain text, then how will we come to know which is header, which is sub header and which is  actuual content or headline in the webiste page. \n",
    "\n",
    "We should create first a html file and then scrap data from that file as per our need. Html of a website save this category in a certain manner under certain tag. such as title tag for headlines. in this case we extract the headline of webiste page using title tag from html."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e32d8b4",
   "metadata": {},
   "source": [
    "### 2. What is Web scrappinng?\n",
    "\n",
    "Web scraping is the process of collecting and parsing(analyzing text in a logical manner)  raw data from the Web\n",
    "\n",
    "Thre are following methods to scrap data from web:\n",
    "- Parse website data using string methods and regular expressions\n",
    "- Parse website data using an HTML parser\n",
    "- Interact with forms and other website components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33cd57f",
   "metadata": {},
   "source": [
    "### 3. Can a website put restriction on its data being scrapped?\n",
    "\n",
    " Some websites explicitly forbid users from scraping their data with automated tools like the ones you’ll create in this tutorial. Websites do this for two possible reasons:\n",
    "- The site has a good reason to protect its data. For instance, Google Maps doesn’t let you request too many results too quickly.\n",
    "- Making many repeated requests to a website’s server may use up bandwidth, slowing down the website for other users and potentially overloading the server such that the website stops responding entirely.\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaf56bd",
   "metadata": {},
   "source": [
    "### 4. Lets make our First Web Scrapper in 6 Steps.\n",
    "\n",
    "Urlib request > import urlopen > open url > real the html. bytes > decode the bytes in ot string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "967e2393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4\n",
      "<http.client.HTTPResponse object at 0x7fa1b9dd95e0> \n",
      "\n",
      "Step 5\n",
      "b'<html>\\n<head>\\n<title>Profile: Aphrodite</title>\\n</head>\\n<body bgcolor=\"yellow\">\\n<center>\\n<br><br>\\n<img src=\"/static/aphrodite.gif\" />\\n<h2>Name: Aphrodite</h2>\\n<br><br>\\nFavorite animal: Dove\\n<br><br>\\nFavorite color: Red\\n<br><br>\\nHometown: Mount Olympus\\n</center>\\n</body>\\n</html>\\n' \n",
      "\n",
      "Step 6 \n",
      " Final Output \n",
      "\n",
      "<html>\n",
      "<head>\n",
      "<title>Profile: Aphrodite</title>\n",
      "</head>\n",
      "<body bgcolor=\"yellow\">\n",
      "<center>\n",
      "<br><br>\n",
      "<img src=\"/static/aphrodite.gif\" />\n",
      "<h2>Name: Aphrodite</h2>\n",
      "<br><br>\n",
      "Favorite animal: Dove\n",
      "<br><br>\n",
      "Favorite color: Red\n",
      "<br><br>\n",
      "Hometown: Mount Olympus\n",
      "</center>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "\n",
      " This were steps to just scrap the html (string converted ) from url. Now we will read text from HTML\n",
      " Note that utf-8 means changing the coding from bytes to string for human understanding\n"
     ]
    }
   ],
   "source": [
    "#1. Lets use urlib: an inbuilt library made to work with urls.\n",
    "\n",
    "#2. The urllib has module \"request\" that contains a function called urlopen() that can be used to open a URL.\n",
    "from urllib.request import urlopen\n",
    "\n",
    "#3 Select a url you want to open\n",
    "url = \"http://olympus.realpython.org/profiles/aphrodite\"\n",
    "\n",
    "#4 Use urlopen() command to open the url\n",
    "page = urlopen(url)\n",
    "print(\"Step 4\")\n",
    "print(page,\"\\n\")\n",
    "      \n",
    "      \n",
    "#5. Url will be saved an object in python. Use read() command to extract html from the webpage...\n",
    "#html is always saved in bytes.\n",
    "html_bytes = page.read()\n",
    "print(\"Step 5\")\n",
    "print(html_bytes,\"\\n\")\n",
    "\n",
    "#6 output gives us result in html bytes. With the hemp of decode(\"utf-8\"). we can gdecode the bytes to a string.\n",
    "html = html_bytes.decode(\"utf-8\")\n",
    "#Note that utf-8 means changing the coding from bytes to string for human understanding\n",
    "\n",
    "\n",
    "\n",
    "print(\"Step 6\",\"\\n\",\"Final Output\",\"\\n\")\n",
    "print(html)\n",
    "\n",
    "print(\"\\n\",\"This were steps to just scrap the html (string converted ) from url. Now we will read text from HTML\")\n",
    "print(\" Note that utf-8 means changing the coding from bytes to string for human understanding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8c6298",
   "metadata": {},
   "source": [
    "### 5. Extract TITLE Text From HTML \n",
    "\n",
    "The < title > HTML element defines the document's title that is shown in a browser's title bar or a page's tab.\n",
    "    \n",
    "\n",
    "- HTML always save the title of the URL between title start and end i.e\"< title >\" and \"< /title >\" respectively\n",
    "- There are four  steps to find the title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c96d069d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: In real word, Title will not be as clean as in this/. Because sometimes the exact substring <title> doesn’t exist and/it impact our slicing at Step 4.In these cases we have to sit and find solution for title with proper slicing\n"
     ]
    }
   ],
   "source": [
    "#Step 1: Find starting index of titke using .find() function\n",
    "title_index = html.find(\"<title>\")\n",
    "title_index\n",
    "\n",
    "#Step 2: Adding len of <title> in step 1 output\n",
    "start_index = title_index + len(\"<title>\")\n",
    "start_index\n",
    "\n",
    "#Step 3: Last index of title end\n",
    "end_index = html.find(\"</title>\")\n",
    "end_index\n",
    "\n",
    "#Step 4: Slicing the Html to get title\n",
    "title = html[start_index:end_index]\n",
    "title\n",
    "\n",
    "print(\"Note: In real word, Title will not be as clean as in this/\\\n",
    ". Because sometimes the exact substring <title> doesn’t exist and/\\\n",
    "it impact our slicing at Step 4.In these cases we have to sit and find solution for title with proper slicing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd09c943",
   "metadata": {},
   "source": [
    "### 3. Extracting Text using Regular Expressions\n",
    "\n",
    "Regular expressions—or regexes for short—are patterns that can be used to search for text within a string. Python supports regular expressions through the standard library’s re module.\n",
    "\n",
    "Regular expressions use special characters called metacharacters to denote different patterns. For instance, the asterisk character (*) stands for zero or more of whatever comes just before the asterisk\n",
    "\n",
    "Before Starting extracting text from HTML First lets undedtand few function to extract text from strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa594ca",
   "metadata": {},
   "source": [
    "#### - Using findall Function from regular expression library\n",
    "\n",
    "Takes two argyment: 1. Text to be serached while logical expression, 2. String to be checked from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c72c7838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ac']\n",
      "Note: If match is not present, Empty list will be returned \n",
      "\n",
      "['ABC']\n",
      "['abcdefc']\n"
     ]
    }
   ],
   "source": [
    "#Lets find a text(with regulkar expression) from a string using findall function from re\n",
    "import re\n",
    "\n",
    "\n",
    "#1. Use (*)\n",
    "#(*) stands for zero or more of whatever comes just before the asterisk.\n",
    "print(re.findall(\"ab*c\", \"ac\"))\n",
    "#\"ab*c\" can be seen as --\n",
    "#Pick part of string that starts with a\n",
    "#end with c\n",
    "#may or may not have b in between\n",
    "#You can see Some Extra Examples:\n",
    "re.findall(\"ab*c\", \"abcd\")\n",
    "re.findall(\"ab*c\", \"acc\")\n",
    "re.findall(\"ab*c\", \"abcac\")\n",
    "re.findall(\"ab*c\", \"abdc\")\n",
    "#In last exmaple. regular expession does have d do, nothing will return\n",
    "print(\"Note: If match is not present, Empty list will be returned\",\"\\n\")\n",
    "#Pattern matching is case sensitive\n",
    "print(re.findall(\"ab*c\", \"ABC\", re.IGNORECASE))\n",
    "\n",
    "\n",
    "#2. Use (.) \n",
    "# (.) stand for any single character in a regular expression.\n",
    "# Mean you could find all the strings that contain the letters \"a\" and \"c\" separated by a single character as follows:\n",
    "re.findall(\"a.c\", \"abc\")\n",
    "#You can see Some Extra Examples:\n",
    "re.findall(\"a.c\", \"abc\")\n",
    "re.findall(\"a.c\", \"abbc\")\n",
    "re.findall(\"a.c\", \"ac\")\n",
    "re.findall(\"a.c\", \"acc\")\n",
    "\n",
    "\n",
    "#3. Use(.*)\n",
    "# The pattern .* inside a regular expression stands for any character repeated any number of times\n",
    "print(re.findall(\"a.*c\", \"abcdefc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe05b1e",
   "metadata": {},
   "source": [
    "#### - Using re.search( ) funtion\n",
    "\n",
    "This function is somewhat more complicated than re.findall() because it returns an object called a MatchObject that stores different groups of data. This is because there might be matches inside other matches, and re.search() returns every possible result.\n",
    "\n",
    "For now, just know that calling .group() on a MatchObject will return the first and most inclusive result, which in most cases is just what you want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "58ff260d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABC'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_results = re.search(\"ab*c\", \"ABC\", re.IGNORECASE)\n",
    "match_results\n",
    "match_results.group()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c8bc4",
   "metadata": {},
   "source": [
    "#### - Using re.sub()\n",
    "\n",
    "is short for substitute, allows you to replace text in a string that matches a regular expression with new text. It behaves sort of like the .replace() string method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "02fc2286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is ELEPHANTS.\n",
      "Note: Dont get surprised. Actually python replaced all values starting from first< to last>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Everything is ELEPHANTS if it's in ELEPHANTS.\""
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"Everything is <replaced> if it's in <tags>.\"\n",
    "string = re.sub(\"<.*>\", \"ELEPHANTS\", string)\n",
    "print(string)\n",
    "print(\"Note: Dont get surprised. Actually python replaced all values starting from first< to last>\")\n",
    "\n",
    "#If you want all < > values to be replaced separatly. Use operator \"?\"\n",
    "string = \"Everything is <replaced> if it's in <tags>.\"\n",
    "string = re.sub(\"<.*?>\", \"ELEPHANTS\", string)\n",
    "string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fbbc6c",
   "metadata": {},
   "source": [
    "### 4. Extracting  Text from HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61769eba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
